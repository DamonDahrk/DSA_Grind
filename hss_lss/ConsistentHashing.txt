Consistent Hashing:

Consistent hashing offers a more scalable and efficient solution by ensuring that only a small fraction of users are reassigned 
when scaling up or down.

Consistent hashing is a distributed hashing technique used to efficiently distribute data across 
multiple nodes (servers, caches, etc.).

It uses a circular hash space (hash ring) with a large and constant hash space.

Both nodes (servers, caches, or databases) and keys (data items) are mapped to positions
 on this hash ring using a hash function.

 In consistent hashing, when the number of nodes changes, only k/n keys need to be reassigned,
  where k is the total number of keys and n is the total number of nodes.

  Instead of distributing keys based on Hash(key) mod N, 
  consistent hashing places both servers and keys on a circular hash ring.

  Defining the Hash Space
We use a large, fixed hash space ranging from 0 to 2^32 - 1 (assuming a 32-bit hash function).

This creates a circular structure, where values wrap around after reaching the maximum limit.

Each server (node) is assigned a position on the hash ring by computing Hash(server_id).

Using the above example with 5 servers (S0, S1, S2, S3, S4), the hash function distributes 
them at different positions around the ring.


When a key is added, its position is determined by computing Hash(key).

Example: a user’s request is assigned a position on the ring based on the hash of their IP address: Hash(IP Address)

We then move clockwise around the ring until we find the next available server.

The key (or request) is assigned to this server for storage or retrieval.

2 Adding a New Server

Suppose we add a new server (S5) to the system.

The position of S5 falls between S1 and S2 in the hash ring.

S5 takes over all keys (requests) that fall between S1 and S5, 
which were previously handled by S2.

Example: User D’s requests which were originally assigned to S2, 
will now be redirected to S5.

This demonstrates how consistent hashing efficiently redistributes keys with minimal disruption, 
ensuring that only a small subset of keys are reassigned when new servers are added.

3 Removing a Node

When a server, such as S4, fails or is removed from the system:

All keys previously assigned to S4 are reassigned to the next available server 
in the ring (S3).

Only the keys (requests) that were mapped to S4 need to move, while all other 
keys remain unaffected.

This results in minimal data movement, unlike traditional hashing where
 removing a node would require reassigning most keys.

3. Virtual Nodes
In basic consistent hashing, each server is assigned a single position on the hash ring. However,
 this can lead to uneven data distribution, especially when:

 The number of servers is small.

Some servers accidentally get clustered together, creating hot spots.

A server is removed, causing a sudden load shift to its immediate neighbor.

With virtual nodes, each server is hashed multiple times:
Now, instead of just one point, S1 is represented at multiple positions, making the 
distribution more even.
If S1 fails, its keys are more evenly redistributed among S2 and S3, 
rather than all going to S2.

